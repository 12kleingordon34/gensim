{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia training\n",
    "\n",
    "In this tutorial we will:\n",
    " - Learn how to train the NMF topic model on English Wikipedia corpus\n",
    " - Compare it with LDA model\n",
    " - Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import smart_open\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim import matutils\n",
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wikipedia dump\n",
    "Let's use `gensim.downloader.api` for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data = api.load(\"wiki-english-20171001\")\n",
    "article = next(iter(data))\n",
    "\n",
    "for section_title, section_text in zip(\n",
    "    article['section_titles'],\n",
    "    article['section_texts']\n",
    "):\n",
    "    print(\"Section title: %s\" % section_title)\n",
    "    print(\"Section text: %s\" % section_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and save articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def save_preprocessed_articles(filename, articles):\n",
    "    with smart_open(filename, 'w+', encoding=\"utf8\") as writer:\n",
    "        for article in tqdm_notebook(articles):\n",
    "            article_text = \" \".join(\n",
    "                \" \".join(section)\n",
    "                for section\n",
    "                in zip(\n",
    "                    article['section_titles'],\n",
    "                    article['section_texts']\n",
    "                )\n",
    "            )\n",
    "            article_text = preprocess_string(article_text)\n",
    "\n",
    "            writer.write(json.dumps(article_text) + '\\n')\n",
    "\n",
    "\n",
    "def get_preprocessed_articles(filename):\n",
    "    with smart_open(filename, 'r', encoding=\"utf8\") as reader:\n",
    "        for line in tqdm_notebook(reader):\n",
    "            yield json.loads(\n",
    "                line\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SAVE_ARTICLES = False\n",
    "\n",
    "if SAVE_ARTICLES:\n",
    "    save_preprocessed_articles('wiki_articles.jsonlines', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_DICTIONARY = False\n",
    "\n",
    "if SAVE_DICTIONARY:\n",
    "    dictionary = Dictionary(get_preprocessed_articles('wiki_articles.jsonlines'))\n",
    "    dictionary.save('wiki.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and filter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load('wiki.dict')\n",
    "dictionary.filter_extremes()\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MmCorpus wrapper\n",
    "In this way we'll:\n",
    "\n",
    "- Make sure that documents are shuffled\n",
    "- Be able to train-test split corpus without rewriting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class RandomCorpus(MmCorpus):\n",
    "    def __init__(self, random_seed=42, testset=False, testsize=1000, *args,\n",
    "                 **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        random_state = np.random.RandomState(random_seed)\n",
    "        self.indices = random_state.permutation(range(self.num_docs))[:4000]\n",
    "        if testset:\n",
    "            self.indices = self.indices[:testsize]\n",
    "        else:\n",
    "            self.indices = self.indices[testsize:]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for doc_id in self.indices:\n",
    "            yield self[doc_id]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_CORPUS = False\n",
    "\n",
    "if SAVE_CORPUS:\n",
    "    corpus = (\n",
    "        dictionary.doc2bow(article)\n",
    "        for article\n",
    "        in get_preprocessed_articles('wiki_articles.jsonlines')\n",
    "    )\n",
    "    \n",
    "    RandomCorpus.serialize('wiki.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test corpus\n",
    "Using `RandomCorpus` wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train_corpus = RandomCorpus(\n",
    "    random_seed=42, testset=False, testsize=2000, fname='wiki.mm'\n",
    ")\n",
    "test_corpus = RandomCorpus(\n",
    "    random_seed=42, testset=True, testsize=2000, fname='wiki.mm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_time(func):\n",
    "    start = time.time()\n",
    "\n",
    "    result = func()\n",
    "\n",
    "    return (time.time() - start), result\n",
    "\n",
    "\n",
    "def get_tm_metrics(model, test_corpus):\n",
    "    W = model.get_topics().T\n",
    "    H = np.zeros((model.num_topics, len(test_corpus)))\n",
    "    for bow_id, bow in enumerate(test_corpus):\n",
    "        for topic_id, word_count in model.get_document_topics(bow):\n",
    "            H[topic_id, bow_id] = word_count\n",
    "\n",
    "    pred_factors = W.dot(H)\n",
    "    pred_factors /= pred_factors.sum(axis=0)\n",
    "    \n",
    "    dense_corpus = matutils.corpus2dense(test_corpus, pred_factors.shape[0])\n",
    "\n",
    "    perplexity = get_tm_perplexity(pred_factors, dense_corpus)\n",
    "\n",
    "    l2_norm = get_tm_l2_norm(pred_factors, dense_corpus)\n",
    "\n",
    "    model.normalize = True\n",
    "\n",
    "    coherence = CoherenceModel(\n",
    "        model=model,\n",
    "        corpus=test_corpus,\n",
    "        coherence='u_mass'\n",
    "    ).get_coherence()\n",
    "\n",
    "    topics = model.show_topics()\n",
    "\n",
    "    model.normalize = False\n",
    "\n",
    "    return dict(\n",
    "        perplexity=perplexity,\n",
    "        coherence=coherence,\n",
    "        topics=topics,\n",
    "        l2_norm=l2_norm,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_tm_perplexity(pred_factors, dense_corpus):\n",
    "    return np.exp(-(np.log(pred_factors, where=pred_factors > 0) * dense_corpus).sum() / dense_corpus.sum())\n",
    "\n",
    "\n",
    "def get_tm_l2_norm(pred_factors, dense_corpus):\n",
    "    return np.linalg.norm(dense_corpus / dense_corpus.sum(axis=0) - pred_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define dataframe in which we'll store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_metrics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define common params for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    corpus=train_corpus,\n",
    "    chunksize=2000,\n",
    "    num_topics=50,\n",
    "    id2word=dictionary,\n",
    "    passes=1,\n",
    "    eval_every=10,\n",
    "    minimum_probability=0,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NMF and save it\n",
    "Normalization is turned off to compute metrics correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dict()\n",
    "row['model'] = 'nmf'\n",
    "row['train_time'], nmf = get_execution_time(\n",
    "    lambda: Nmf(\n",
    "        use_r=False,\n",
    "        normalize=False,\n",
    "        **params\n",
    "    )\n",
    ")\n",
    "nmf.save('nmf.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NMF and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = Nmf.load('nmf.model')\n",
    "row.update(get_tm_metrics(nmf, test_corpus))\n",
    "tm_metrics = tm_metrics.append(pd.Series(row), ignore_index=True)\n",
    "\n",
    "nmf.show_topics(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train NMF with residuals and save it\n",
    "Residuals add regularization to the model thus increasing quality, but slows down training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row = dict()\n",
    "row['model'] = 'nmf_with_r'\n",
    "row['train_time'], nmf_with_r = get_execution_time(\n",
    "    lambda: Nmf(\n",
    "        use_r=True,\n",
    "        lambda_=200,\n",
    "        normalize=False,\n",
    "        **params\n",
    "    )\n",
    ")\n",
    "nmf_with_r.save('nmf_with_r.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NMF with residuals and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_with_r = Nmf.load('nmf_with_r.model')\n",
    "row.update(get_tm_metrics(nmf_with_r, test_corpus))\n",
    "tm_metrics = tm_metrics.append(pd.Series(row), ignore_index=True)\n",
    "\n",
    "nmf_with_r.show_topics(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LDA and save it\n",
    "That's a common model to do Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = dict()\n",
    "row['model'] = 'lda'\n",
    "row['train_time'], lda = get_execution_time(\n",
    "    lambda: LdaModel(**params)\n",
    ")\n",
    "lda.save('lda.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LDA and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel.load('lda.model')\n",
    "row.update(get_tm_metrics(lda, test_corpus))\n",
    "tm_metrics = tm_metrics.append(pd.Series(row), ignore_index=True)\n",
    "\n",
    "lda.show_topics(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx, row in tm_metrics.iterrows():\n",
    "    print('='*20)\n",
    "    print(row['model'])\n",
    "    print('='*20)\n",
    "    print()\n",
    "    print(\"\\n\\n\".join(str(topic) for topic in row['topics']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DISCLAIMER: this section will be edited when run on full corpus`\n",
    "\n",
    "As we can see, NMF can be significantly faster than LDA without sacrificing quality of topics too much (or not sacrificing at all)\n",
    "\n",
    "Moreover, NMF can be very flexible on RAM usage due to sparsity option, which leaves only small amount of elements in inner matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
