{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia training\n",
    "\n",
    "### In this tutorial we will:\n",
    " - Learn how to train the NMF topic model on the English Wikipedia corpus\n",
    " - Compare it with LDA and Sklearn NMF\n",
    " - Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from smart_open import smart_open\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "from contextlib import contextmanager\n",
    "from multiprocessing import Process\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import joblib\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim import matutils\n",
    "from gensim.corpora import MmCorpus, Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim.models.nmf import Nmf as GensimNmf\n",
    "from sklearn.decomposition.nmf import NMF as SklearnNmf\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wikipedia dump\n",
    "Let's use `gensim.downloader.api` for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section title: Introduction\n",
      "Section text: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'''Anarchism''' is a political philosophy that advocates self-governed societies based on volun\n",
      "Section title: Etymology and terminology\n",
      "Section text: \n",
      "\n",
      "The word ''anarchism'' is composed from the word ''anarchy'' and the suffix ''-ism'', themselves d\n",
      "Section title: History\n",
      "Section text: \n",
      "\n",
      "===Origins===\n",
      "Woodcut from a Diggers document by William Everard\n",
      "\n",
      "The earliest anarchist themes ca\n",
      "Section title: Anarchist schools of thought\n",
      "Section text: \n",
      "Portrait of philosopher Pierre-Joseph Proudhon (1809–1865) by Gustave Courbet. Proudhon was the pri\n",
      "Section title: Internal issues and debates\n",
      "Section text: \n",
      "consistent with anarchist values is a controversial subject among anarchists.\n",
      "\n",
      "Anarchism is a philo\n",
      "Section title: Topics of interest\n",
      "Section text: Intersecting and overlapping between various schools of thought, certain topics of interest and inte\n",
      "Section title: Criticisms\n",
      "Section text: \n",
      "Criticisms of anarchism include moral criticisms and pragmatic criticisms. Anarchism is often evalu\n",
      "Section title: See also\n",
      "Section text: * Anarchism by country\n",
      "\n",
      "Section title: References\n",
      "Section text: \n",
      "\n",
      "Section title: Further reading\n",
      "Section text: * Barclay, Harold, ''People Without Government: An Anthropology of Anarchy'' (2nd ed.), Left Bank Bo\n",
      "Section title: External links\n",
      "Section text: \n",
      "* \n",
      "* \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = api.load(\"wiki-english-20171001\")\n",
    "article = next(iter(data))\n",
    "\n",
    "for section_title, section_text in zip(\n",
    "    article['section_titles'],\n",
    "    article['section_texts']\n",
    "):\n",
    "    print(\"Section title: %s\" % section_title)\n",
    "    print(\"Section text: %s\" % section_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess and save articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def save_preprocessed_articles(filename, articles):\n",
    "    with smart_open(filename, 'w+', encoding=\"utf8\") as writer:\n",
    "        for article in tqdm_notebook(articles):\n",
    "            article_text = \" \".join(\n",
    "                \" \".join(section)\n",
    "                for section\n",
    "                in zip(\n",
    "                    article['section_titles'],\n",
    "                    article['section_texts']\n",
    "                )\n",
    "            )\n",
    "            article_text = preprocess_string(article_text)\n",
    "\n",
    "            writer.write(json.dumps(article_text) + '\\n')\n",
    "\n",
    "\n",
    "def get_preprocessed_articles(filename):\n",
    "    with smart_open(filename, 'r', encoding=\"utf8\") as reader:\n",
    "        for line in tqdm_notebook(reader):\n",
    "            yield json.loads(\n",
    "                line\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "SAVE_ARTICLES = False\n",
    "\n",
    "if SAVE_ARTICLES:\n",
    "    save_preprocessed_articles('wiki_articles.jsonlines', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_DICTIONARY = False\n",
    "\n",
    "if SAVE_DICTIONARY:\n",
    "    dictionary = Dictionary(get_preprocessed_articles('wiki_articles.jsonlines'))\n",
    "    dictionary.save('wiki.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and filter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 22:27:02,588 : INFO : loading Dictionary object from wiki.dict\n",
      "2019-02-06 22:27:03,510 : INFO : loaded wiki.dict\n",
      "2019-02-06 22:27:09,054 : INFO : discarding 1910146 tokens: [('abdelrahim', 49), ('abstention', 120), ('anarcha', 101), ('anarchica', 40), ('anarchosyndicalist', 20), ('antimilitar', 68), ('arbet', 194), ('archo', 100), ('arkhē', 5), ('autonomedia', 118)]...\n",
      "2019-02-06 22:27:09,055 : INFO : keeping 100000 tokens which were in no less than 5 and no more than 2462447 (=50.0%) documents\n",
      "2019-02-06 22:27:09,956 : INFO : resulting dictionary: Dictionary(100000 unique tokens: ['tago', 'süß', 'akrita', 'divert', 'construccion']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary.load('wiki.dict')\n",
    "dictionary.filter_extremes()\n",
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MmCorpus wrapper\n",
    "In this way we'll:\n",
    "\n",
    "- Make sure that documents are shuffled\n",
    "- Be able to train-test split corpus without rewriting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class RandomCorpus(MmCorpus):\n",
    "    def __init__(self, random_seed=42, testset=False, testsize=1000, *args,\n",
    "                 **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        random_state = np.random.RandomState(random_seed)\n",
    "        \n",
    "        self.indices = random_state.permutation(range(self.num_docs))\n",
    "        test_nnz = sum(len(self[doc_idx]) for doc_idx in self.indices[:testsize])\n",
    "        \n",
    "        if testset:\n",
    "            self.indices = self.indices[:testsize]\n",
    "            self.num_docs = testsize\n",
    "            self.num_nnz = test_nnz\n",
    "        else:\n",
    "            self.indices = self.indices[testsize:]\n",
    "            self.num_docs -= testsize\n",
    "            self.num_nnz -= test_nnz\n",
    "\n",
    "    def __iter__(self):\n",
    "        for doc_id in self.indices:\n",
    "            yield self[doc_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and save corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAVE_CORPUS = False\n",
    "\n",
    "if SAVE_CORPUS:\n",
    "    corpus = (\n",
    "        dictionary.doc2bow(article)\n",
    "        for article\n",
    "        in get_preprocessed_articles('wiki_articles.jsonlines')\n",
    "    )\n",
    "    \n",
    "    RandomCorpus.serialize('wiki.mm', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test corpus\n",
    "Using `RandomCorpus` wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 22:27:10,847 : INFO : loaded corpus index from wiki.mm.index\n",
      "2019-02-06 22:27:10,847 : INFO : initializing cython corpus reader from wiki.mm\n",
      "2019-02-06 22:27:10,848 : INFO : accepted corpus with 4924894 documents, 100000 features, 683326444 non-zero entries\n",
      "2019-02-06 22:27:17,213 : INFO : loaded corpus index from wiki.mm.index\n",
      "2019-02-06 22:27:17,215 : INFO : initializing cython corpus reader from wiki.mm\n",
      "2019-02-06 22:27:17,218 : INFO : accepted corpus with 4924894 documents, 100000 features, 683326444 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "train_corpus = RandomCorpus(\n",
    "    random_seed=42, testset=False, testsize=2000, fname='wiki.mm'\n",
    ")\n",
    "test_corpus = RandomCorpus(\n",
    "    random_seed=42, testset=True, testsize=2000, fname='wiki.mm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert corpora to csc and save\n",
    "\n",
    "It's necessary in order to train Sklearn NMF. These matrices take **a lot** of RAM even though they're sparse (about 8GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_CSC = False\n",
    "\n",
    "if SAVE_CSC:\n",
    "    train_csc = matutils.corpus2csc(train_corpus, len(dictionary))\n",
    "    scipy.sparse.save_npz('train_csc.npz', train_csc)\n",
    "    \n",
    "    test_csc = matutils.corpus2csc(test_corpus, len(dictionary))\n",
    "    scipy.sparse.save_npz('test_csc.npz', test_csc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- `train time` - time to train a model\n",
    "- `mean_ram` - mean RAM consumption during the training\n",
    "- `max_ram` - maximum RAM consumpiton during the training\n",
    "- `perplexity` - perplexity score. Another usual TM metric\n",
    "- `coherence` - coherence score (not defined for sklearn NMF). Classic metric for topic models.\n",
    "- `l2_norm` - l2 norm of `v - Wh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def measure_ram(output, tick=2):\n",
    "    def _measure_ram(pid, output, start_memory, tick=5):\n",
    "        py = psutil.Process(pid)\n",
    "        with open(output, 'w') as outfile:\n",
    "            while True:\n",
    "                memory = py.memory_info().rss - start_memory\n",
    "                outfile.write(\"{}\\n\".format(memory))\n",
    "                outfile.flush()\n",
    "                time.sleep(tick)\n",
    "\n",
    "    pid = os.getpid()\n",
    "    start_memory = psutil.Process(pid).memory_info().rss\n",
    "    p = Process(target=_measure_ram, args=(pid, output, start_memory, 5))\n",
    "    p.start()\n",
    "    yield\n",
    "    p.terminate()\n",
    "\n",
    "def get_train_time_and_ram(func, name):\n",
    "    memprof_filename = \"{}.memprof\".format(name)\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    with measure_ram(memprof_filename, 5):\n",
    "        result = func()        \n",
    "        \n",
    "    elapsed_time = pd.to_timedelta(time.time() - start, unit='s').round('s')\n",
    "    \n",
    "    memprof_df = pd.read_csv(memprof_filename, squeeze=True)\n",
    "    \n",
    "    mean_ram = \"{} MB\".format(\n",
    "        int(memprof_df.mean() // 2**20),\n",
    "    )\n",
    "    \n",
    "    max_ram = \"{} MB\".format(int(memprof_df.max() // 2**20))\n",
    "\n",
    "    return elapsed_time, mean_ram, max_ram, result\n",
    "\n",
    "\n",
    "def get_tm_metrics(model, test_corpus):\n",
    "    W = model.get_topics().T\n",
    "    H = np.zeros((model.num_topics, len(test_corpus)))\n",
    "    for bow_id, bow in enumerate(test_corpus):\n",
    "        for topic_id, word_count in model.get_document_topics(bow):\n",
    "            H[topic_id, bow_id] = word_count\n",
    "\n",
    "    pred_factors = W.dot(H)\n",
    "    \n",
    "    dense_corpus = matutils.corpus2dense(test_corpus, pred_factors.shape[0])\n",
    "\n",
    "    l2_norm = get_tm_l2_norm(pred_factors, dense_corpus)\n",
    "    \n",
    "    pred_factors /= pred_factors.sum(axis=0)\n",
    "    \n",
    "    perplexity = get_tm_perplexity(pred_factors, dense_corpus)\n",
    "\n",
    "    model.normalize = True\n",
    "\n",
    "    coherence = CoherenceModel(\n",
    "        model=model,\n",
    "        corpus=test_corpus,\n",
    "        coherence='u_mass'\n",
    "    ).get_coherence()\n",
    "    \n",
    "    topics = model.show_topics(5)\n",
    "\n",
    "    model.normalize = False\n",
    "\n",
    "    return dict(\n",
    "        perplexity=round(perplexity, 4),\n",
    "        coherence=round(coherence, 4),\n",
    "        l2_norm=round(l2_norm, 4),\n",
    "        topics=topics,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_tm_perplexity(pred_factors, dense_corpus):\n",
    "    return np.exp(-(np.log(pred_factors, where=pred_factors > 0) * dense_corpus).sum() / dense_corpus.sum())\n",
    "\n",
    "\n",
    "def get_tm_l2_norm(pred_factors, dense_corpus):\n",
    "    return np.linalg.norm(dense_corpus - pred_factors)\n",
    "\n",
    "\n",
    "def get_sklearn_topics(model, id2word, top_n=5):\n",
    "    topic_probas = model.components_.T\n",
    "    topic_probas = topic_probas / topic_probas.sum(axis=0)\n",
    "    \n",
    "    sparsity = np.zeros(topic_probas.shape[1])\n",
    "\n",
    "    for row in topic_probas:\n",
    "        sparsity += (row == 0)\n",
    "\n",
    "    sparsity /= topic_probas.shape[1]\n",
    "    \n",
    "    topic_probas = topic_probas[:, sparsity.argsort()[::-1]][:, :top_n]\n",
    "    \n",
    "    token_indices = topic_probas.argsort(axis=0)[:-11:-1, :]\n",
    "    topic_probas.sort(axis=0)\n",
    "    topic_probas = topic_probas[:-11:-1, :]\n",
    "    \n",
    "    topics = []\n",
    "    \n",
    "    for topic_idx in range(topic_probas.shape[1]):\n",
    "        tokens = [\n",
    "            id2word[token_idx]\n",
    "            for token_idx\n",
    "            in token_indices[:, topic_idx]\n",
    "        ]\n",
    "        topic = (\n",
    "            '{}*\"{}\"'.format(round(proba, 3), token)\n",
    "            for proba, token\n",
    "            in zip(topic_probas[:, topic_idx], tokens)\n",
    "        )\n",
    "        topic = \" + \".join(topic)\n",
    "        topics.append((topic_idx, topic))\n",
    "    \n",
    "    return topics\n",
    "\n",
    "\n",
    "def get_sklearn_metrics(model, test_corpus, dictionary):\n",
    "    W = model.components_.T\n",
    "    H = model.transform((test_corpus).T).T\n",
    "    pred_factors = W.dot(H)\n",
    "    \n",
    "    l2_norm = np.linalg.norm(test_corpus - pred_factors)\n",
    "    \n",
    "    pred_factors /= pred_factors.sum(axis=0)\n",
    "\n",
    "    perplexity = np.exp(\n",
    "        -(np.log(pred_factors, where=pred_factors > 0) * test_corpus).sum()\n",
    "        / test_corpus.sum()\n",
    "    )\n",
    "    \n",
    "    topics = get_sklearn_topics(model, dictionary, top_n=5)\n",
    "\n",
    "    return dict(\n",
    "        perplexity=perplexity,\n",
    "        l2_norm=l2_norm,\n",
    "        topics=topics,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataframe in which we'll store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_metrics = pd.DataFrame(columns=[\n",
    "    'model', 'train_time', 'mean_ram', 'max_ram', 'perplexity', 'coherence', 'l2_norm', 'topics'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define common params for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    corpus=train_corpus,\n",
    "    chunksize=2000,\n",
    "    num_topics=50,\n",
    "    id2word=dictionary,\n",
    "    passes=1,\n",
    "    eval_every=10,\n",
    "    minimum_probability=0,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Gensim NMF and save it\n",
    "Normalization is turned off to compute metrics correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 22:28:18,836 : INFO : Loss: 0.04683116478141604\n",
      "2019-02-06 22:28:47,687 : INFO : Loss: 0.03585093916474252\n",
      "2019-02-06 22:29:03,704 : INFO : Loss: 0.016218137567651437\n",
      "=============\n",
      "==TRUNCATED==\n",
      "=============\n",
      "2019-02-06 22:52:21,184 : INFO : Loss: 0.00019501346145086494\n",
      "2019-02-06 22:52:26,080 : INFO : Loss: 0.00010551328334260371\n",
      "2019-02-06 22:52:30,927 : INFO : Loss: 0.0001089520591937033\n",
      "2019-02-06 22:52:35,753 : INFO : Loss: 0.0\n",
      "2019-02-06 22:52:36,577 : INFO : Loss: 0.00030404947061429366\n",
      "2019-02-06 22:52:36,589 : INFO : saving Nmf object under gensim_nmf.model, separately None\n",
      "2019-02-06 22:52:36,966 : INFO : saved gensim_nmf.model\n"
     ]
    }
   ],
   "source": [
    "row = dict()\n",
    "row['model'] = 'gensim_nmf'\n",
    "row['train_time'], row['mean_ram'], row['max_ram'], nmf = get_train_time_and_ram(\n",
    "    lambda: GensimNmf(\n",
    "        normalize=False,\n",
    "        **params\n",
    "    ),\n",
    "    'gensim_nmf',\n",
    ")\n",
    "\n",
    "nmf.save('gensim_nmf.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Gensim NMF and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 22:52:36,983 : INFO : loading Nmf object from gensim_nmf.model\n",
      "2019-02-06 22:52:37,292 : INFO : loading id2word recursively from gensim_nmf.model.id2word.* with mmap=None\n",
      "2019-02-06 22:52:37,293 : INFO : loaded gensim_nmf.model\n",
      "/home/anotherbugmaster/gensim/gensim/matutils.py:503: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n",
      "2019-02-06 22:53:31,168 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "2019-02-06 22:53:31,278 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n"
     ]
    }
   ],
   "source": [
    "nmf = GensimNmf.load('gensim_nmf.model')\n",
    "row.update(get_tm_metrics(nmf, test_corpus))\n",
    "tm_metrics = tm_metrics.append(pd.Series(row), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LDA and save it\n",
    "That's a common model to do Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-06 22:53:31,779 : INFO : using symmetric alpha at 0.02\n",
      "2019-02-06 22:53:31,780 : INFO : using symmetric eta at 0.02\n",
      "2019-02-06 22:53:31,798 : INFO : using serial LDA version on this node\n",
      "2019-02-06 22:53:32,320 : INFO : running online (single-pass) LDA training, 50 topics, 1 passes over the supplied corpus of 4922894 documents, updating model once every 2000 documents, evaluating perplexity every 20000 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-02-06 22:53:32,473 : INFO : PROGRESS: pass 0, at document #2000/4922894\n",
      "2019-02-06 22:53:34,391 : INFO : merging changes from 2000 documents into a model of 4922894 documents\n",
      "2019-02-06 22:53:34,709 : INFO : topic #36 (0.020): 0.006*\"new\" + 0.005*\"record\" + 0.004*\"servic\" + 0.004*\"includ\" + 0.003*\"year\" + 0.003*\"state\" + 0.003*\"design\" + 0.003*\"work\" + 0.003*\"time\" + 0.003*\"american\"\n",
      "2019-02-06 22:53:34,711 : INFO : topic #19 (0.020): 0.005*\"team\" + 0.005*\"new\" + 0.004*\"nation\" + 0.004*\"state\" + 0.004*\"includ\" + 0.003*\"time\" + 0.003*\"apollo\" + 0.003*\"year\" + 0.002*\"unit\" + 0.002*\"level\"\n",
      "2019-02-06 22:53:34,713 : INFO : topic #42 (0.020): 0.004*\"new\" + 0.004*\"text\" + 0.004*\"year\" + 0.004*\"member\" + 0.003*\"time\" + 0.003*\"state\" + 0.003*\"world\" + 0.003*\"univers\" + 0.003*\"work\" + 0.003*\"nation\"\n",
      "2019-02-06 22:53:34,715 : INFO : topic #43 (0.020): 0.006*\"state\" + 0.005*\"year\" + 0.005*\"includ\" + 0.005*\"elect\" + 0.003*\"game\" + 0.003*\"nation\" + 0.003*\"school\" + 0.003*\"new\" + 0.003*\"road\" + 0.003*\"music\"\n",
      "2019-02-06 22:53:34,716 : INFO : topic #5 (0.020): 0.010*\"album\" + 0.004*\"year\" + 0.004*\"new\" + 0.003*\"state\" + 0.003*\"born\" + 0.003*\"record\" + 0.003*\"includ\" + 0.003*\"song\" + 0.003*\"releas\" + 0.003*\"chart\"\n",
      "2019-02-06 22:53:34,725 : INFO : topic diff=40.889942, rho=1.000000\n",
      "2019-02-06 22:53:34,899 : INFO : PROGRESS: pass 0, at document #4000/4922894\n",
      "=============\n",
      "==TRUNCATED==\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "row = dict()\n",
    "row['model'] = 'lda'\n",
    "row['train_time'], row['mean_ram'], row['max_ram'], lda = get_train_time_and_ram(\n",
    "    lambda: LdaModel(**params),\n",
    "    'lda',\n",
    ")\n",
    "lda.save('lda.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LDA and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-07 00:19:19,731 : INFO : loading LdaModel object from lda.model\n",
      "2019-02-07 00:19:19,734 : INFO : loading expElogbeta from lda.model.expElogbeta.npy with mmap=None\n",
      "2019-02-07 00:19:19,740 : INFO : setting ignored attribute id2word to None\n",
      "2019-02-07 00:19:19,741 : INFO : setting ignored attribute dispatcher to None\n",
      "2019-02-07 00:19:19,742 : INFO : setting ignored attribute state to None\n",
      "2019-02-07 00:19:19,743 : INFO : loaded lda.model\n",
      "2019-02-07 00:19:19,743 : INFO : loading LdaState object from lda.model.state\n",
      "2019-02-07 00:19:19,837 : INFO : loaded lda.model.state\n",
      "/home/anotherbugmaster/gensim/gensim/matutils.py:503: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  result = np.column_stack(sparse2full(doc, num_terms) for doc in corpus)\n",
      "2019-02-07 00:19:41,681 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "2019-02-07 00:19:41,790 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel.load('lda.model')\n",
    "row.update(get_tm_metrics(lda, test_corpus))\n",
    "tm_metrics = tm_metrics.append(pd.Series(row), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Sklearn NMF and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sklearn_nmf.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = dict()\n",
    "row['model'] = 'sklearn_nmf'\n",
    "sklearn_nmf = SklearnNmf(n_components=50, tol=1e-2, random_state=42)\n",
    "row['train_time'], row['mean_ram'], row['max_ram'], sklearn_nmf = get_train_time_and_ram(\n",
    "    lambda: sklearn_nmf.fit(scipy.sparse.load_npz('train_csc.npz').T),\n",
    "    'sklearn_nmf',\n",
    ")\n",
    "\n",
    "joblib.dump(sklearn_nmf, 'sklearn_nmf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sklearn NMF and store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_nmf = joblib.load('sklearn_nmf.joblib')\n",
    "row.update(get_sklearn_metrics(\n",
    "    sklearn_nmf, scipy.sparse.load_npz('test_csc.npz').toarray(), dictionary\n",
    "))\n",
    "tm_metrics = tm_metrics.append(pd.Series(row), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_metrics.replace(np.nan, '-', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_time</th>\n",
       "      <th>mean_ram</th>\n",
       "      <th>max_ram</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>coherence</th>\n",
       "      <th>l2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gensim_nmf</td>\n",
       "      <td>00:25:16</td>\n",
       "      <td>130 MB</td>\n",
       "      <td>165 MB</td>\n",
       "      <td>3741.860600</td>\n",
       "      <td>-2.9857</td>\n",
       "      <td>1983.378700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lda</td>\n",
       "      <td>01:25:48</td>\n",
       "      <td>140 MB</td>\n",
       "      <td>140 MB</td>\n",
       "      <td>4701.976000</td>\n",
       "      <td>-2.5286</td>\n",
       "      <td>2273.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn_nmf</td>\n",
       "      <td>00:49:29</td>\n",
       "      <td>10716 MB</td>\n",
       "      <td>15961 MB</td>\n",
       "      <td>3943.036299</td>\n",
       "      <td>-</td>\n",
       "      <td>1987.280856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model train_time  mean_ram   max_ram   perplexity coherence  \\\n",
       "0   gensim_nmf   00:25:16    130 MB    165 MB  3741.860600   -2.9857   \n",
       "1          lda   01:25:48    140 MB    140 MB  4701.976000   -2.5286   \n",
       "2  sklearn_nmf   00:49:29  10716 MB  15961 MB  3943.036299         -   \n",
       "\n",
       "       l2_norm  \n",
       "0  1983.378700  \n",
       "1  2273.643000  \n",
       "2  1987.280856  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_metrics.drop('topics', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "Gensim NMF is better than Sklearn NMF in every aspect:\n",
    "\n",
    "- **2x** faster\n",
    "\n",
    "\n",
    "- Uses **80x-120x** less memory.\n",
    "\n",
    "    About **8GB** of RAM comes from the input corpus sparse matrices, which, in contrast to Gensim NMF, can't be passed iteratively. But even if we forget about tremendous corpus size, Sklearn NMF still uses about **2-8 GB** of RAM, which is much larger than that of Gensim NMF and LDA.\n",
    "\n",
    "\n",
    "- Still achieves better l2 norm and perplexity\n",
    "\n",
    "Comparing to LDA, Gensim NMF is also better in almost everything:\n",
    "\n",
    "- **3.5x** faster\n",
    "- Achieves much better l2 norm and perplexity\n",
    "\n",
    "Coherence is less than LDA's though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gensim_nmf:\n",
      "(23, '0.007*\"seri\" + 0.006*\"episod\" + 0.006*\"time\" + 0.006*\"appear\" + 0.005*\"later\" + 0.005*\"charact\" + 0.005*\"kill\" + 0.005*\"man\" + 0.004*\"work\" + 0.004*\"book\"')\n",
      "(19, '0.018*\"king\" + 0.012*\"centuri\" + 0.009*\"church\" + 0.007*\"son\" + 0.005*\"princ\" + 0.005*\"french\" + 0.005*\"franc\" + 0.005*\"england\" + 0.005*\"kingdom\" + 0.005*\"year\"')\n",
      "(49, '0.079*\"royal\" + 0.038*\"corp\" + 0.034*\"armi\" + 0.028*\"regiment\" + 0.027*\"capt\" + 0.025*\"townhous\" + 0.020*\"maj\" + 0.020*\"artilleri\" + 0.017*\"servic\" + 0.017*\"col\"')\n",
      "(38, '0.132*\"mount\" + 0.130*\"iatrogen\" + 0.128*\"peak\" + 0.126*\"knightsbridg\" + 0.126*\"somedai\" + 0.065*\"survei\" + 0.027*\"octob\" + 0.023*\"campo\" + 0.023*\"css\" + 0.018*\"septemb\"')\n",
      "(43, '0.197*\"linear\" + 0.196*\"secundaria\" + 0.039*\"newman\" + 0.037*\"septemb\" + 0.034*\"parallax\" + 0.027*\"octob\" + 0.023*\"knightsbridg\" + 0.023*\"anderson\" + 0.023*\"montana\" + 0.023*\"lanc\"')\n",
      "\n",
      "lda:\n",
      "(35, '0.054*\"russian\" + 0.039*\"soviet\" + 0.032*\"russia\" + 0.027*\"polish\" + 0.026*\"republ\" + 0.025*\"philippin\" + 0.020*\"pollin\" + 0.020*\"moscow\" + 0.016*\"ukrainian\" + 0.015*\"union\"')\n",
      "(23, '0.136*\"award\" + 0.071*\"best\" + 0.034*\"year\" + 0.028*\"japan\" + 0.023*\"japanes\" + 0.023*\"nomin\" + 0.019*\"foundri\" + 0.018*\"intern\" + 0.018*\"won\" + 0.014*\"prize\"')\n",
      "(8, '0.027*\"law\" + 0.023*\"court\" + 0.018*\"state\" + 0.017*\"act\" + 0.012*\"right\" + 0.012*\"case\" + 0.010*\"report\" + 0.010*\"polic\" + 0.008*\"legal\" + 0.007*\"judg\"')\n",
      "(2, '0.046*\"island\" + 0.039*\"ship\" + 0.018*\"navi\" + 0.014*\"sea\" + 0.012*\"port\" + 0.012*\"boat\" + 0.011*\"class\" + 0.011*\"naval\" + 0.010*\"folli\" + 0.010*\"coast\"')\n",
      "(11, '0.023*\"john\" + 0.011*\"william\" + 0.011*\"david\" + 0.011*\"jame\" + 0.010*\"robert\" + 0.009*\"michael\" + 0.008*\"smith\" + 0.008*\"georg\" + 0.008*\"paul\" + 0.008*\"richard\"')\n",
      "\n",
      "sklearn_nmf:\n",
      "(0, '0.338*\"township\" + 0.039*\"pennsylvania\" + 0.037*\"counti\" + 0.02*\"arah\" + 0.013*\"bowhead\" + 0.013*\"ohio\" + 0.012*\"creek\" + 0.01*\"commun\" + 0.009*\"town\" + 0.009*\"road\"')\n",
      "(1, '0.124*\"state\" + 0.01*\"law\" + 0.01*\"court\" + 0.009*\"feder\" + 0.008*\"govern\" + 0.006*\"member\" + 0.005*\"tax\" + 0.005*\"pennsylvania\" + 0.005*\"senat\" + 0.005*\"repres\"')\n",
      "(2, '0.176*\"linear\" + 0.175*\"secundaria\" + 0.048*\"septemb\" + 0.036*\"newman\" + 0.035*\"octob\" + 0.032*\"parallax\" + 0.025*\"august\" + 0.024*\"decemb\" + 0.023*\"knightsbridg\" + 0.023*\"peak\"')\n",
      "(3, '0.118*\"mount\" + 0.116*\"iatrogen\" + 0.115*\"peak\" + 0.114*\"knightsbridg\" + 0.113*\"somedai\" + 0.058*\"survei\" + 0.041*\"octob\" + 0.037*\"septemb\" + 0.023*\"novemb\" + 0.021*\"css\"')\n",
      "(4, '0.195*\"conserv\" + 0.129*\"labour\" + 0.088*\"liber\" + 0.014*\"west\" + 0.013*\"north\" + 0.013*\"unionist\" + 0.012*\"east\" + 0.012*\"south\" + 0.009*\"cow\" + 0.007*\"member\"')\n"
     ]
    }
   ],
   "source": [
    "def compare_topics(tm_metrics):\n",
    "    for _, row in tm_metrics.iterrows():\n",
    "        print('\\n{}:'.format(row.model))\n",
    "        print(\"\\n\".join(str(topic) for topic in row.topics))\n",
    "        \n",
    "compare_topics(tm_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like all models have successfully learned the topic representation of the corpus."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
